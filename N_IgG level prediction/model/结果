gradientboost
MSE 1.344603144110577
MAE 0.8728418174802516
RMSE 1.1595702411284006
R^2 0.06508726829306065


randomforest
MSE: 1.294262757764584
MAE: 0.8591015610379884
RMSE: 1.1376566959169114
R: 0.0888061963542331

scad
RMSE: 1.1500650335156286
MSE: 1.3226495813153039
MAE: 0.9035438491065639
R: 0.10347363709474018

lstm
MSE: 1.2679535150527954
RMSE: 1.1260343790054321
MAE: 0.8523229956626892
R-squared: 0.12440804560747419

elastic_net
RMSE: 1.0800227161600464
MSE: 1.166449067421724
MAE: 0.8431781520219908
R: 0.1138009646826113


seq2seq+attention
普通的注意力机制的结果
RMSE: 1.07285
MSE: 1.15100
MAE: 0.83390
R-squared: 0.19061
用广义加性模型代替注意力机制后的结果
代替后的数据

RMSE: 1.06658
MSE: 1.13760
MAE: 0.82953
R-squared: 0.24092


seq2seq_NA
RMSE: 1.07449
MSE: 1.15454
MAE: 0.83570
R-squared: 0.23535

GAM
MSE 1.2332416865117244
MAE 0.8705653810517187
RMSE 1.110514154124892
R^2 0.13887316690235474






